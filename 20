# rbm_rnn_lstm.py
# Purpose: show RBM (sklearn), RNN and LSTM (Keras) performance on simple datasets
# Run in Colab/Jupyter. Requires: scikit-learn, tensorflow, numpy

import numpy as np
from sklearn import datasets
from sklearn.neural_network import BernoulliRBM
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.datasets import imdb
np.random.seed(42)
tf.random.set_seed(42)

# --------------------------
# Part A: RBM on sklearn digits (binarized)
# --------------------------
digits = datasets.load_digits()
X = digits.data
y = (digits.target == 0).astype(int)  # binary task: is digit 0 or not (example)
# Binarize features (0/1) for BernoulliRBM
X_bin = (X > X.mean(axis=0)).astype(int)

X_tr, X_te, y_tr, y_te = train_test_split(X_bin, y, test_size=0.25, random_state=42, stratify=y)
rbm = BernoulliRBM(n_components=64, learning_rate=0.01, batch_size=10, n_iter=20, random_state=42)
logistic = LogisticRegression(max_iter=1000, solver='lbfgs')
pipe = Pipeline([('rbm', rbm), ('logistic', logistic)])
pipe.fit(X_tr, y_tr)
y_pred = pipe.predict(X_te)
print("\nRBM + Logistic on Digits (0 vs not 0):")
print("Accuracy:", accuracy_score(y_te, y_pred))
print(classification_report(y_te, y_pred))

# --------------------------
# Part B: Simple RNN on IMDB (binary sentiment)
# --------------------------
max_features = 6000
maxlen = 200
(x_tr, y_tr), (x_te, y_te) = imdb.load_data(num_words=max_features)
x_tr = pad_sequences(x_tr, maxlen=maxlen)
x_te = pad_sequences(x_te, maxlen=maxlen)

def make_rnn():
    model = models.Sequential([
        layers.Embedding(max_features, 32, input_length=maxlen),
        layers.SimpleRNN(32),
        layers.Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

rnn = make_rnn()
rnn.fit(x_tr[:20000], y_tr[:20000], validation_data=(x_te[:5000], y_te[:5000]), epochs=3, batch_size=128, verbose=1)
loss_rnn, acc_rnn = rnn.evaluate(x_te[:5000], y_te[:5000], verbose=0)
print("\nSimpleRNN test accuracy (subset):", acc_rnn)

# --------------------------
# Part C: LSTM on IMDB
# --------------------------
def make_lstm():
    model = models.Sequential([
        layers.Embedding(max_features, 32, input_length=maxlen),
        layers.LSTM(64),
        layers.Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

lstm = make_lstm()
lstm.fit(x_tr[:20000], y_tr[:20000], validation_data=(x_te[:5000], y_te[:5000]), epochs=3, batch_size=128, verbose=1)
loss_lstm, acc_lstm = lstm.evaluate(x_te[:5000], y_te[:5000], verbose=0)
print("\nLSTM test accuracy (subset):", acc_lstm)
